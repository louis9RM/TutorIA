# ğŸ“ TutorIA â€” Asistente Educativo con Voz + RAG + Llama 3.1 (Open Source)

![TutorIA Banner](https://user-images.githubusercontent.com/0000000/tutoria-banner.png)

**TutorIA** es un asistente inteligente en espaÃ±ol que responde **con voz y texto**, utilizando modelos **open-source** completamente locales.  
No depende de servicios en la nube ni APIs de pago.

> ğŸ§  *â€œAprende, explica y enseÃ±a como un tutor humano, pero desde tu computadora.â€*

---

## ğŸš€ CaracterÃ­sticas principales

âœ… 100 % **local y privado** â€” sin conexiÃ³n a Internet ni servicios externos  
âœ… **Responde en espaÃ±ol**, con voz natural (TTS)  
âœ… **RAG**: Recupera informaciÃ³n desde tus propios documentos  
âœ… **Modelo Llama 3.1 (8B)** ejecutÃ¡ndose en **Ollama**  
âœ… **Frontend web** con entrada y salida por voz  
âœ… Compatible con **Windows, Linux y macOS**

---

## ğŸ§° TecnologÃ­as usadas

| Componente | DescripciÃ³n | Herramienta |
|-------------|--------------|-------------|
| ğŸ Backend API | Servidor principal | **FastAPI + Uvicorn** |
| ğŸ¤– LLM | Modelo de lenguaje local | **Llama 3.1 (8B)** via **Ollama** |
| ğŸ” RAG | BÃºsqueda semÃ¡ntica contextual | **SentenceTransformers (MiniLM)** |
| ğŸ”Š TTS | Voz en espaÃ±ol | **espeak-ng** |
| ğŸŒ Frontend | Interfaz web vozâ†”voz | **HTML + JavaScript (Web Speech API)** |
| ğŸ³ Contenedores | OrquestaciÃ³n y aislamiento | **Docker + Docker Compose** |
| ğŸªŸ OS | Entorno de ejecuciÃ³n | **Windows 11 / Linux / macOS** |

---

## ğŸ“¦ Requisitos previos

Antes de empezar, asegÃºrate de tener instalado:

1. **Docker Desktop**  
   ğŸ‘‰ [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)

2. **Git**  
   ğŸ‘‰ [https://git-scm.com/downloads](https://git-scm.com/downloads)

3. (Opcional) **PowerShell 7+** para Windows.

---

## ğŸªœ InstalaciÃ³n paso a paso

### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/<TU_USUARIO>/TutorIA.git
cd TutorIA
```

---

### 2ï¸âƒ£ Estructura del proyecto

```
TutorIA/
 â”œâ”€ app/                â†’ CÃ³digo principal (FastAPI, RAG, TTS)
 â”œâ”€ data/               â†’ Documentos para bÃºsqueda local
 â”œâ”€ web/                â†’ Interfaz cliente (HTML + JS)
 â”œâ”€ Dockerfile          â†’ Imagen del backend
 â”œâ”€ docker-compose.yml  â†’ OrquestaciÃ³n de contenedores
 â”œâ”€ requirements.txt    â†’ Dependencias de Python
 â”œâ”€ .env                â†’ Variables de entorno
 â”œâ”€ .gitignore
 â””â”€ README.md
```

---

### 3ï¸âƒ£ Configurar variables de entorno

Crea el archivo `.env` en la raÃ­z del proyecto:

```env
# Puerto del servidor API
PORT=8000

# DirecciÃ³n del contenedor Ollama
OLLAMA_URL=http://ollama:11434

# Modelo LLM (descargado automÃ¡ticamente)
MODEL_NAME=llama3.1

# Lenguaje del TTS
VOICE_LANG=es
```

---

### 4ï¸âƒ£ Construir y ejecutar con Docker

```bash
docker compose up --build -d
```

Esto levanta:
- ğŸ§  **ollama** â†’ modelo Llama 3.1  
- ğŸ™ **tutor-ia** â†’ API FastAPI (RAG + TTS)

Verifica que ambos contenedores estÃ©n activos:
```bash
docker compose ps
```

---

### 5ï¸âƒ£ Descargar el modelo Llama 3.1

Una sola vez:

```bash
docker exec -it ollama ollama pull llama3.1
```

---

### 6ï¸âƒ£ Verificar el servicio

Prueba el endpoint de salud:
```bash
Invoke-WebRequest http://localhost:8000/health
```
DeberÃ­a responder:
```json
{"status":"ok"}
```

---

## ğŸ—£ï¸ Prueba de funcionamiento

### OpciÃ³n 1 â€“ Desde PowerShell
```powershell
$body = @{ question = "Â¿QuÃ© es la energÃ­a solar?"; voice_mode = $true } | ConvertTo-Json
Invoke-RestMethod -Uri "http://localhost:8000/ask" -Method Post -ContentType "application/json; charset=utf-8" -Body $body
```

### OpciÃ³n 2 â€“ Desde el navegador
Abre el archivo:
```
web/index.html
```
Y presiona el botÃ³n ğŸ¤ **â€œHablarâ€**.  
El tutor escucharÃ¡ tu voz, pensarÃ¡ y responderÃ¡ **hablando en espaÃ±ol**.

---

## ğŸ§© Arquitectura del sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Navegador (web)   â”‚  â† Voz/Texto del usuario
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI (tutor-ia)       â”‚
â”‚ - Procesa preguntas         â”‚
â”‚ - Ejecuta RAG               â”‚
â”‚ - EnvÃ­a prompt a Ollama     â”‚
â”‚ - Genera voz (espeak-ng)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ollama + Llama 3.1 (8B)  â”‚
â”‚   Modelo local de lenguaje  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Agregar tus propios documentos (RAG)

Coloca tus archivos `.txt`, `.pdf` o `.md` en la carpeta `data/`.

Luego reinicia el contenedor del backend:
```bash
docker compose restart tutor-ia
```

El sistema indexarÃ¡ automÃ¡ticamente tus documentos para usarlos como contexto.

---

## ğŸ SoluciÃ³n de problemas comunes

| Problema | Causa | SoluciÃ³n |
|-----------|--------|----------|
| âŒ *â€œThere was an error parsing the bodyâ€* | JSON mal formateado | Usa `ConvertTo-Json` en PowerShell |
| ğŸ’¤ *Demora en responder* | CPU sin GPU | Es normal, usa `llama3.1:8b-instruct` o `phi3` para mÃ¡s rapidez |
| âš ï¸ *Caracteres raros (ÃƒÂ³, ÃƒÂ¡)* | Consola sin UTF-8 | Ejecuta `chcp 65001` en PowerShell |
| ğŸ”‡ *No hay voz* | Navegador bloquea audio | Permite micrÃ³fono y altavoz en el navegador |

---
# 1ï¸âƒ£ LEVANTAR OLLAMA CON GPU
docker run -d --gpus all --name ollama -p 11434:11434 ollama/ollama:latest

# Cargar modelo
docker exec -it ollama ollama pull llama3.1

# 2ï¸âƒ£ LEVANTAR BACKEND TUTORIA
cd TutorIA
docker build -t tutoria .
docker run -d --name tutor-ia -p 8000:8000 --env-file .env --link ollama:tutoria-ollama tutoria
---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas!  
Puedes abrir un **issue** o enviar un **pull request** con mejoras, nuevos modelos o voces.

---

## ğŸ§‘â€ğŸ’» Autor

**EVER DEV**  
Desarrollador de soluciones educativas con IA  
ğŸ’¬ [LinkedIn](linkedin.com/in/lino-ever-ramos-maiz-950578387) 

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**.  
Puedes usarlo, modificarlo y compartirlo libremente.

---

## ğŸŒŸ Agradecimientos

- [Ollama](https://ollama.com/) â€” por hacer accesibles los modelos LLM locales  
- [FastAPI](https://fastapi.tiangolo.com/) â€” backend rÃ¡pido y moderno  
- [SentenceTransformers](https://www.sbert.net/) â€” embeddings potentes y ligeros  
- [espeak-ng](https://github.com/espeak-ng/espeak-ng) â€” voz libre en espaÃ±ol

---

> âœ¨ *â€œTutorIA: tu profesor personal, local y libre.â€*
